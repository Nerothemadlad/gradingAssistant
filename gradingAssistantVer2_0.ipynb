{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gradingAssistantVer2.0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO8fae7pSyREqJv7OJurb4w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nerothemadlad/gradingAssistant/blob/main/gradingAssistantVer2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Allow user to upload the CSV file stored on the local computer (which can be downloaded from Google Form) to his/her virtual machine associated with this Jupyter Notebook"
      ],
      "metadata": {
        "id": "SJhmmNVen2kS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8pMaSSg4fGX"
      },
      "source": [
        "from google.colab import files, data_table\n",
        "\n",
        "data_table.enable_dataframe_formatter()\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract the file name from the received CSV file and use it to load the CSV file as a pandas dataframe"
      ],
      "metadata": {
        "id": "TDJuHtX-o1qU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "filename = list(uploaded.keys())[0]\n",
        "df = pd.read_csv(io.BytesIO(uploaded[filename]))\n",
        "df"
      ],
      "metadata": {
        "id": "I3SH_T1qiH8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exclude columns at the beginning or the end that are unrelated to the grading process or require manual evaluation from the table\n",
        "\n",
        "To exclude columns that are not at the beginning or the end without having to code, use *Microsoft Excel* or *Google Sheets*"
      ],
      "metadata": {
        "id": "RroFYsNto_Eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional\n",
        "# Get key informations of the table\n",
        "columns = df.columns\n",
        "rows_number = len(df) - 1 # exclude the teacher\n",
        "\n",
        "def select_columns(columns: list) -> List[int]:\n",
        "  \"\"\"\n",
        "  Select the to be excluded columns, which are unrelated to the grading process\n",
        "  or require manual evaluation\n",
        "\n",
        "  columns: The list contains all columns' names\n",
        "\n",
        "  \"\"\"\n",
        "  while True:\n",
        "    print(\n",
        "        \"Only choose columns unrelated to grading process or required manual evaluation\"\n",
        "    )\n",
        "    columns_at_the_beginning = input(\n",
        "        \"How many columns at the beginning do you wish to exclude (enter 0 for none)? \"\n",
        "    )\n",
        "    columns_at_the_end = input(\n",
        "        \"How many columns at the end do you wish to exclude (enter 0 for none)? \"\n",
        "    )\n",
        "\n",
        "    if not (\n",
        "      columns_at_the_beginning.strip().isnumeric()\n",
        "      and columns_at_the_end.strip().isnumeric()\n",
        "  ):\n",
        "      print(\"Numbers only, please!\")\n",
        "      continue\n",
        "\n",
        "    columns_at_the_beginning = int(columns_at_the_beginning)\n",
        "    columns_at_the_end = int(columns_at_the_end)\n",
        "\n",
        "    return list(range(columns_at_the_beginning)) + list(\n",
        "        range(len(columns) - columns_at_the_end, len(columns))\n",
        "    )\n",
        "\n",
        "unused_columns_indices = select_columns(columns)\n",
        "\n",
        "print(unused_columns_indices)"
      ],
      "metadata": {
        "id": "S_DFZo_AqtvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exclude the unused columns"
      ],
      "metadata": {
        "id": "yU4GU_XCF0qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = columns.delete(unused_columns_indices)\n",
        "questions_number = len(questions)\n",
        "examinee_answers_table = df[questions]"
      ],
      "metadata": {
        "id": "NKegFk3kkYhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluate examinees' answers using the correct answers submitted by the teacher after the exam (located on last row because Google Form auto-sorts answers by submitted times)"
      ],
      "metadata": {
        "id": "EX0doXF6IQ5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# Extract the correct answers on the last row\n",
        "right_answers = list(examinee_answers_table.iloc[rows_number])\n",
        "\n",
        "def evaluate(answer: str, correct_answer: str) -> bool:\n",
        "  \"\"\"\n",
        "  Evaluate each individual answer in the sheet\n",
        "\n",
        "  answer: The examinee answer\n",
        "  correct_answer: The answer submitted by the teacher\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Filter words out of both answers using regex\n",
        "  # handle NaN cases, if correct answer is NaN, NaN == NaN will still return False\n",
        "  # so no exceed scores will be added\n",
        "  if isinstance(answer, float) or isinstance(correct_answer, float):\n",
        "    return answer == correct_answer\n",
        "  keywords = re.split(r'\\W+', answer)\n",
        "  correct_keywords = re.split(r'\\W+', correct_answer)\n",
        "  \n",
        "  # Create a capitalized version of correct answer (high tolerance)\n",
        "  correct_keywords_capitalized = correct_keywords[:]\n",
        "  correct_keywords_capitalized[0] = correct_keywords_capitalized[0].capitalize()\n",
        "\n",
        "  # Get minimal the length of answers and\n",
        "  # determine loop range for redundant answers\n",
        "  minimal_length = len(correct_keywords)\n",
        "  max_loop = len(keywords) - minimal_length + 1\n",
        "\n",
        "  # Handle the case when the answer is too short\n",
        "  if max_loop <= 0:\n",
        "    return False\n",
        "\n",
        "  # Go words by words to avoid error in conjugation\n",
        "  # (e.g: 'like' in 'likes' return True but in reality is still False)\n",
        "  for _ in range(max_loop):\n",
        "    if keywords[_:(_ + minimal_length)] in (correct_keywords, correct_keywords_capitalized):\n",
        "      return True\n",
        "\n",
        "  return False\n",
        "results = []\n",
        "\n",
        "# Iterate over each student's answers and evaluate them\n",
        "for idx, row in examinee_answers_table.iterrows():\n",
        "\n",
        "  # Check if the correct answers is in the examinees' answers\n",
        "  # and add the results (True/False) to a table (nested list)\n",
        "  result = [evaluate(row[idx], x) for idx, x in enumerate(right_answers)]\n",
        "  results.append(result)\n",
        "\n",
        "# Convert the the `True/False` table to a matrix of 0 and 1 using NumPy array\n",
        "# to be used for grading with a score per answer scale vector later\n",
        "results = np.array(results).astype(int)\n",
        "print(f'The results of each examinee (1: right, 0: wrong):\\n{results}')"
      ],
      "metadata": {
        "id": "t7Vv-dk3MeQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Start the grading process\n",
        "Create a score per correct answer scale for grading later."
      ],
      "metadata": {
        "id": "LjFdVlYDKYg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scores_input() -> None:\n",
        "  \"\"\"\n",
        "  Ask user to enter the scores for every correct answer\n",
        "\n",
        "  To be returned variable is made global instead to overwrite the values in \n",
        "  recursive memory/stack, avoid errors with mutable type variable,\n",
        "  increase memory efficiency and made code more readable.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Create a scores scale variable on global scope\n",
        "  global SCORE_PER_CORRECT_ANSWER\n",
        "  SCORE_PER_CORRECT_ANSWER = []\n",
        "  i = 1\n",
        "\n",
        "  while True:\n",
        "\n",
        "    print('Enter \"e\" to exit after finishing.')\n",
        "    total_problems = input(f'Number of questions in problem {i}: ')\n",
        "\n",
        "    if total_problems == 'e':\n",
        "      break\n",
        "\n",
        "    if not total_problems.strip().isnumeric():\n",
        "      print('Numbers only, please!')\n",
        "      continue\n",
        "    \n",
        "    total_problems = int(total_problems)\n",
        "    total_scores = input('Score for this problem: ')\n",
        "\n",
        "    # Code can't be refactored because `continue` can't stand alone outside of loops\n",
        "    if not total_scores.strip().isnumeric():\n",
        "      print('Numbers only, please!')\n",
        "      continue\n",
        "\n",
        "    total_scores = int(total_scores)\n",
        "    # `+=` is used instead of .append() method because it only extends the original list with elements of the new list\n",
        "    # instead of adding the new list as an element to the original list and make a nested list (table)\n",
        "    SCORE_PER_CORRECT_ANSWER += ([total_scores/total_problems] * total_problems)\n",
        "    i += 1\n",
        "  \n",
        "  if len(SCORE_PER_CORRECT_ANSWER) != questions_number:\n",
        "    print(\"\"\"\\nThe number of scores doesn't match the number of questions!\n",
        "          \\nPlease enter the scores again!\\n\"\"\")\n",
        "    scores_input()\n",
        "\n",
        "scores_input()\n",
        "# Convert the scale to a NumPy 1d array representing a vector\n",
        "# to be used for grading in conjunction with the \"results\" matrix\n",
        "SCORE_PER_CORRECT_ANSWER = np.array(SCORE_PER_CORRECT_ANSWER)\n",
        "print(f'\\nScore per correct answer scale:\\n{SCORE_PER_CORRECT_ANSWER}')"
      ],
      "metadata": {
        "id": "OUIgoPsP9l2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you're not interested in the technical details of how the codes work, skip ahead.\n",
        "\n",
        ">***The first line is only a fail safe to explicitly add new axis to the 1d array and make it a 2d \"column vector\" that the \"results\" matrix is mutiplied by. It should have no real effects on the process because a 1d NumPy array is normally treated as a 2d \"column vector\". But it will sometimes be automatically broadcasted to a 2d \"row vector\" which can cause the multiplication to fail.***\n",
        "\n",
        "The second line calculates score for each answer using matrix (results) by vector (score_per_correct_answer) multiplication. You can also use other libraries like `Numba`, `Cython` or `operator` to perform the multiplication if you find `NumPy`'s auto broadcasting concept confusing."
      ],
      "metadata": {
        "id": "4wfrBYBie9br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SCORE_PER_CORRECT_ANSWER[:, np.newaxis]\n",
        "scores = results * SCORE_PER_CORRECT_ANSWER\n",
        "print(f'The score for every question:\\n{scores}')"
      ],
      "metadata": {
        "id": "S63KASCcJ3nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count the questions in each individual part/section of the exam (i.e. listening, reading, grammatic part in language exams)."
      ],
      "metadata": {
        "id": "X0_l83lyMzZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def part_questions_counter() -> None:\n",
        "  \"\"\"\n",
        "  Ask user to enter questions number of each section\n",
        "\n",
        "  \"\"\"\n",
        "  \n",
        "  global PARTS_QUESTIONS\n",
        "  PARTS_QUESTIONS = []\n",
        "  i = 1\n",
        "\n",
        "  while True:\n",
        "\n",
        "    print('Enter \"e\" to exit after finishing.')\n",
        "    part_questions = input(f'Number of questions in part {i}: ')\n",
        "\n",
        "    if part_questions == 'e':\n",
        "      break\n",
        "\n",
        "    if not part_questions.strip().isnumeric():\n",
        "      print('Numbers only, please!')\n",
        "      continue\n",
        "    \n",
        "    part_questions = int(part_questions)\n",
        "    PARTS_QUESTIONS.append(part_questions)\n",
        "    i += 1\n",
        "  \n",
        "  if sum(PARTS_QUESTIONS) != questions_number:\n",
        "    print(\"\"\"\\nNumber of questions in all parts doesn't match the number of questions!\n",
        "      \\nPlease enter the scores again!\\n\"\"\")\n",
        "    part_questions_counter()\n",
        "\n",
        "print(f\"If the exam doesn't have multiple sections, enter {questions_number} and then 'e' to exit:\")\n",
        "part_questions_counter()\n",
        "print(f'Number of questions in each part:\\n{PARTS_QUESTIONS}')"
      ],
      "metadata": {
        "id": "kCvvmvItMyio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the scores for every part in the exam and save these values to a dictionary object."
      ],
      "metadata": {
        "id": "0br6_A9Uy8Rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import islice\n",
        "\n",
        "# Create tuples containing keys for dictionaries\n",
        "parts = tuple([f'Part {x + 1}' for x in range(len(PARTS_QUESTIONS))])\n",
        "def ask_for_name_id_column() -> int:\n",
        "  while True:\n",
        "    name_id_column = input('Names/IDs are at column number: ')\n",
        "\n",
        "    if not name_id_column.strip().isnumeric():\n",
        "      print('Numbers only, please!')\n",
        "      continue\n",
        "    \n",
        "    return int(name_id_column)\n",
        "\n",
        "name_id_column = ask_for_name_id_column()\n",
        "\n",
        "examinees = tuple(df.iloc[:rows_number, name_id_column - 1])\n",
        "examinees_scores = []\n",
        "\n",
        "def sum_score_for_all_parts(score: list) -> list:\n",
        "  \"\"\"\n",
        "  Calculate the section scores of an examinee\n",
        "\n",
        "  score: the list containing scores for every answer of an examinee\n",
        "\n",
        "  \"\"\"\n",
        "  part_scores = list()\n",
        "  score = iter(score)\n",
        "\n",
        "  for value in PARTS_QUESTIONS:\n",
        "    part_scores.append(sum(islice(score, value)))\n",
        "  \n",
        "  return part_scores\n",
        "\n",
        "# Calculate the maximum scores for every part\n",
        "maximum_scores = scores[rows_number]\n",
        "scores = scores[:rows_number]\n",
        "maximum_score_per_part = sum_score_for_all_parts(maximum_scores)\n",
        "\n",
        "# Zip the score to the respective part\n",
        "for score in scores:\n",
        "  examinee_scores = dict(zip(parts, sum_score_for_all_parts(score)))\n",
        "  examinees_scores.append(examinee_scores)\n",
        "\n",
        "# Zip the scores to the respective examinee\n",
        "examinees_scores = dict(zip(examinees, examinees_scores))\n",
        "examinees_scores"
      ],
      "metadata": {
        "id": "r3oOt-jUeATW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the dictionary object to a pandas dataframe and scale the scores for each part (per user choice)"
      ],
      "metadata": {
        "id": "8Kc5JmgA1Gmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores_table = pd.DataFrame.from_dict(examinees_scores, orient='index')\n",
        "def scale_the_scores() -> Optional[float]:\n",
        "  while True:\n",
        "    print('To not scale the scores, enter \"e\" to exit.')\n",
        "    user_input = input('The maximum score of the scale: ')\n",
        "\n",
        "    if user_input == 'e':\n",
        "      return None\n",
        "\n",
        "    if not user_input.strip().isnumeric():\n",
        "        print('Numbers only, please!')\n",
        "        continue\n",
        "    \n",
        "    return float(user_input)\n",
        "\n",
        "scale = scale_the_scores()\n",
        "if scale:\n",
        "  for idx, maximum_score in enumerate(maximum_score_per_part):\n",
        "    scores_table.iloc[:, idx] = round((scores_table.iloc[:, idx]/maximum_score)*scale, 1)\n",
        "\n",
        "scores_table"
      ],
      "metadata": {
        "id": "G0jlBcwGa2rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Export the data as an excel file and save it to the local machine"
      ],
      "metadata": {
        "id": "2hVojMQYjvfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_filename = filename.split('.')[0] + '_scores.xlsx'\n",
        "scores_table.to_excel(output_filename)\n",
        "files.download(output_filename)"
      ],
      "metadata": {
        "id": "TY3KzzbZ0N1A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}